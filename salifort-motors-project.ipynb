{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Capstone project: Providing data-driven suggestions for HR","metadata":{"id":"ysS5rgTMWpwL"}},{"cell_type":"markdown","source":"### Business scenario and problem\n\nThe HR department at Salifort Motors wants to take some initiatives to improve employee satisfaction levels at the company. They collected data from employees, but now they don’t know what to do with it. They refer to you as a data analytics professional and ask you to provide data-driven suggestions based on your understanding of the data. They have the following question: what’s likely to make the employee leave the company?\n\nYour goals in this project are to analyze the data collected by the HR department and to build a model that predicts whether or not an employee will leave the company.\n\nIf you can predict employees likely to quit, it might be possible to identify factors that contribute to their leaving. Because it is time-consuming and expensive to find, interview, and hire new employees, increasing employee retention will be beneficial to the company.","metadata":{"id":"gLEEr6peWcF7"}},{"cell_type":"code","source":"# Import packages\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import f_oneway\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","metadata":{"id":"hVWGpX9As4e1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf0 = pd.read_csv(\"HR_capstone_dataset.csv\")\n\n\ndf0.head(10)","metadata":{"id":"Bs0cJR5BDPgQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df0.info()","metadata":{"id":"6XbfdPoKurMf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Descriptive statistics about the data","metadata":{"id":"6JMl_rQ1Fgte"}},{"cell_type":"code","source":"df0.describe()","metadata":{"id":"_5VRL-kzE8y1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Renaming columns","metadata":{"id":"QR7eFNU0FklJ"}},{"cell_type":"code","source":"df0.columns","metadata":{"id":"kEn21u2bqrEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Renaming columns as needed\ndf0.rename(columns={'satisfaction_level': 'satisfaction',\n                   'number_project':'projects',\n                    'average_montly_hours': 'average_monthly_hours',\n                     'time_spend_company':'time_spent',\n                      'work_accident':'has_work_accident',\n                       'promotion_last_5years':'has_promotion_last_5years',\n                        'Department':'department'}, inplace=True)\n\n","metadata":{"id":"npUQA8jMFJQD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check missing values","metadata":{"id":"e-G2QlQxBq__"}},{"cell_type":"code","source":"# Checking for missing values\ndf0.isnull().sum()","metadata":{"id":"EN9MvN0GByVV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check duplicates","metadata":{"id":"hBvrijItKQI9"}},{"cell_type":"code","source":"# Checking for duplicates\ndf0.duplicated().sum()","metadata":{"id":"CFFLc5AOZ7-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspecting some rows containing duplicates as needed\ndf0[df0.duplicated()]","metadata":{"id":"ZHGlDbKAcBLM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Droping duplicates and saving resulting dataframe \ndf0 = df0.drop_duplicates()\n\ndf0.head(5)","metadata":{"id":"wCr34Rppdjay"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check outliers","metadata":{"id":"4knHIoTIFu83"}},{"cell_type":"code","source":"# Creating a boxplot to visualize distributions and detect any outliers\nnumerical_cols = df0.iloc[:,:7]\nfor col in numerical_cols[numerical_cols.columns]:\n    plt.figure(figsize=(5,1))\n    sns.boxplot(x=numerical_cols[col], fliersize=1)\n    plt.title( f'{col} box plot');\n","metadata":{"id":"pilaGYgh4LHM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#number of rows containing outliers\n\ndf0[df0[\"time_spent\"]>= 6]","metadata":{"id":"ohctgiHyFykI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df0 = df0.sort_values(by='satisfaction', ascending=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df0.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# numbers of people who left vs. stayed\nprint(\"people who left vs. stayed\")\nprint(\"How many?\")\nprint(df0[\"left\"].value_counts())\n\n# Percentages of people who left vs. stayed\nprint(\"In what percentages?\")\nprint(df0[\"left\"].value_counts() / len(df0[\"left\"]) * 100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data visualizations","metadata":{"id":"DmVMzXPSuYk1"}},{"cell_type":"code","source":"for col in numerical_cols.columns:\n    plt.figure(figsize=(5, 3))  \n    sns.histplot(numerical_cols[col], kde=True )\n    median = df0[col].median()\n    plt.axvline(median, color='red', linestyle='--')\n    plt.title(f'{col} Histogram')\n    plt.show()","metadata":{"id":"Qf0VbjX8-DBQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df0)","metadata":{"id":"F8HlhjMy9X3A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What is the mean satisfaction , last evaluation , average monthly hours and time spent of each employee who left and who doesn't?\ndf0.groupby(\"left\")[['satisfaction', 'last_evaluation', 'average_monthly_hours',\n       'time_spent']].mean()","metadata":{"id":"NUyBruMee-EI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What is the mean satisfaction , last evaluation , average monthly hours and time spent in each category of salary?\ndf0.groupby(\"salary\")[['satisfaction', 'last_evaluation', 'average_monthly_hours',\n       'time_spent']].mean()","metadata":{"id":"UCVs81NILbhn","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What is the mean satisfaction , last evaluation , average monthly hours and time spent in each department?\ndf0.groupby(\"department\")[['satisfaction', 'last_evaluation', 'average_monthly_hours',\n       'time_spent']].mean()","metadata":{"id":"cGitCvzvdbjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How many employees left in each department?\ndf0.groupby(\"department\")[\"left\"].sum()","metadata":{"id":"6TyBo1uxsSpc","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df0.groupby(\"salary\")[\"satisfaction\"].mean()  \n#are the differences statistically significant?#######","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = []\nfor salary, group in df0.groupby('salary')['satisfaction']:\n    groups.append(group)\n\nresult = f_oneway(*groups)\nalpha = 0.05\nif result.pvalue < alpha:\n    print(\"There are significant differences in satisfaction means among salary categories.\")\nelse:\n    print(\"There are no significant differences in satisfaction means among salary categories.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#what is the salary of each employee who left?\ndf0.groupby(\"salary\")[\"left\"].sum()","metadata":{"id":"lfo96dwwruZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what is the mode salary of each of the departments?\ndf0.groupby('department')['salary'].apply(lambda x: x.mode().iloc[0]).reset_index()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9,10))\nsns.scatterplot(x=df0[\"last_evaluation\"],y=df0[\"average_monthly_hours\"],hue=df0[\"left\"] )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.scatterplot(data=df0, x='average_monthly_hours', y='salary', hue='left', palette='coolwarm', alpha=0.7)\nplt.xlabel(\"Average Monthly Hours\")\nplt.ylabel(\"Salary\")\nplt.title(\"Number of Employees Left by Salary and Average Monthly Hours\")\nplt.legend(title=\"Left\", labels=[\"Left\", \" Not left\"], loc='upper left', bbox_to_anchor=(1.02, 1.0))\n\nplt.tight_layout()\nplt.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import pointbiserialr\ncorrelation_coefficient, p_value = pointbiserialr(df0['average_monthly_hours'], df0['left'])\nalpha = 0.05  \nif p_value < alpha:\n    print(\"There is a statistically significant relationship between the two variables.\")\nelse:\n    print(\"There is no statistically significant relationship between the two variables.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\ncontingency_table = pd.crosstab(df0['salary'], df0['left'])\n\nchi2, p_value, dof, expected = chi2_contingency(contingency_table)\n\nalpha = 0.05\n\nif p_value < alpha:\n    print(\"There is a statistically significant relationship between the salary and the left variable.\")\nelse:\n    print(\"There is no statistically significant relationship between the salary and the left variable.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# how many hours work the majority of people who left?\nmask_left = df0[\"left\"] == 1\n\nmask_salary = (df0[\"salary\"] == \"medium\") | (df0[\"salary\"] == \"low\")\n\ncombined_mask = mask_left & mask_salary\n\ndf0[\"average_monthly_hours\"][combined_mask].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import pearsonr\ncorrelation_coefficient, p_value = pearsonr(df0['has_promotion_last_5years'], df0['satisfaction'])\n\nalpha = 0.05  \nif p_value < alpha:\n    print(\"There is a statistically significant relationship between has_promotion_last_5years and satisfaction.\")\nelse:\n    print(\"There is no statistically significant relationship between has_promotion_last_5years and satisfaction  .\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_coefficient, p_value = pearsonr(df0['last_evaluation'], df0['satisfaction'])\n\nalpha = 0.05  \nif p_value < alpha:\n    print(\"There is a statistically significant relationship between last_evaluation and satisfaction.\")\nelse:\n    print(\"There is no statistically significant relationship between last_evaluation and satisfaction  .\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_coefficient, p_value = pearsonr(df0['last_evaluation'], df0['average_monthly_hours'])\n\nalpha = 0.05  \nif p_value < alpha:\n    print(\"There is a statistically significant relationship between last_evaluation and average_monthly_hours.\")\nelse:\n    print(\"There is no statistically significant relationship between last_evaluation and average_monthly_hours  .\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_coefficient, p_value = pearsonr(df0['left'], df0['satisfaction'])\n\nalpha = 0.05  \nif p_value < alpha:\n    print(\"There is a statistically significant relationship between left and satisfaction.\")\nelse:\n    print(\"There is no statistically significant relationship between left and satisfaction .\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\ncorr = df0.corr()\nsns.heatmap(corr, vmin=0, vmax=1)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.boxplot(x='left', y='last_evaluation', data=df0, palette='pastel')\nplt.xlabel('Left (0: Not Left, 1: Left)')\nplt.ylabel('Last Evaluation')\nplt.title('Distribution of Last Evaluation for Different \"Left\" Categories')\nplt.show()\n\n\nplt.figure(figsize=(8, 6))\nsns.violinplot(x='left', y='last_evaluation', data=df0, palette='pastel')\nplt.xlabel('Left (0: Not Left, 1: Left)')\nplt.ylabel('Last Evaluation')\nplt.title('Distribution of Last Evaluation for Different \"Left\" Categories')\nplt.show()\n\ncorrelation_matrix = df0[['last_evaluation', 'average_monthly_hours', 'satisfaction', 'left']].corr()\nplt.figure(figsize=(8, 6))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights","metadata":{"id":"DeTmNVlAANLd"}},{"cell_type":"markdown","source":"* 59% of people who left have a low salary and almost 39% have a medium one.\n* The majority of people who left are in technical(19,58% of all employees who left) , support(15,67% of all employees who left) and especially the sales department (27,62% of all employees who left); and the most frequent salary in all these three is low  .\n* There is a statistically significant relationship between last_evaluation and satisfaction.\n* There is a statistically significant relationship between last_evaluation and average_monthly_hours.\n* There is a statistically significant relationship between has_promotion_last_5years and satisfaction.\n* There is a statistically significant relationship between left and satisfaction.\n* There are significant differences in satisfaction means among salary categories(low,medium, high).\n* There is a statistically significant relationship between average monthly hours and employees who left.\n* There is a statistically significant relationship between the salary and the left variable.\n* The employees who left are divided into two groups : low evaluations and the majority who have higher evaluations.\n* The majority of employees who left have a high evaluation but their working hours are more than average.\n\n\n------------------------------------------------------------------------------------------------------------------\n\n<b><span style=\"font-size: 24px;\">As a conclusion: the majority of employees who left are working on average  208 hours , and they have low salary (59%) and medium salary (39%); And the most affected department is Sales.</span></b>\n\n\n-------------------------------------------------------------------------------------------------------------------","metadata":{"id":"sQT8YqymD-yL"}},{"cell_type":"markdown","source":"### Modeling\n\n","metadata":{"id":"OrW2oXy4OfD1"}},{"cell_type":"code","source":"### YOUR CODE HERE ###\nfrom sklearn.model_selection import PredefinedSplit, cross_val_score\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\n","metadata":{"id":"UePZZyi_Okdz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ndf0['salary'] = label_encoder.fit_transform(df0['salary'])\ndf0 = pd.get_dummies(df0, columns=['department'], drop_first=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX = df0.drop(\"left\", axis=1)\ny = df0[\"left\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state = 0)\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.25,random_state = 0)\n","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n    \"XGBClassifier\": XGBClassifier(objective='binary:logistic',random_state=0)\n}\n\n# Define hyperparameter grids for each model\ncv_param = {\n    \"DecisionTreeClassifier\": {'max_depth': [3, 5, 7]},\n    \"RandomForestClassifier\": {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7]},\n    \"XGBClassifier\": {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7]}\n}\nscoring = {'accuracy', 'precision', 'recall', 'f1'}\nsplit_index = [0 if x in X_val.index else -1 for x in X_train.index]\ncustom_split = PredefinedSplit(split_index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params_dict = {}  # Dictionary to store the best hyperparameters of each model\n\nfor model_name, model in models.items():\n    model_gs = GridSearchCV(model, cv_param[model_name], scoring=scoring, cv=custom_split, refit='f1')\n    model_gs.fit(X_train, y_train)\n    best_model = model_gs.best_estimator_\n\n    # Store the best hyperparameters of each model in the dictionary\n    best_params_dict[model_name] = model_gs.best_params_\n\n    # Evaluate the model on validation set\n    y_val_pred = best_model.predict(X_val)\n    val_accuracy = accuracy_score(y_val, y_val_pred)\n    val_precision = precision_score(y_val, y_val_pred)\n    val_recall = recall_score(y_val, y_val_pred)\n    val_f1 = f1_score(y_val, y_val_pred)\n\n    print(f\"Model: {model_name}\")\n    print(f\"Validation Accuracy: {val_accuracy:.4f}, Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}, Validation F1: {val_f1:.4f}\")\n    print(\"---------------------------------------------------------\")\n\n\n\nbest_params_xgb = best_params_dict[\"XGBClassifier\"]\nprint(\"Best Hyperparameters for XGBoostClassifier:\")\nprint(best_params_xgb)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XGB_optimal = XGBClassifier(max_depth=3, n_estimators=300,random_state=1)\nXGB_optimal.fit(X_train, y_train)\ny_pred = XGB_optimal.predict(X_test)\npc_test = precision_score(y_test, y_pred)\nprint(\"The precision score is {pc:.3f}\".format(pc = pc_test))\nrc_test = recall_score(y_test, y_pred)\nprint(\"The recall score is {rc:.3f}\".format(rc = rc_test))\nac_test = accuracy_score(y_test, y_pred)\nprint(\"The accuracy score is {ac:.3f}\".format(ac = ac_test))\nf1_test = f1_score(y_test, y_pred)\nprint(\"The F1 score is {f1:.3f}\".format(f1 = f1_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncm = confusion_matrix(y_test, y_pred, labels=XGB_optimal.classes_)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=XGB_optimal.classes_, cmap='viridis', normalize='true')\ndisp.plot(cmap='viridis', include_values=True, xticks_rotation='horizontal', values_format='.2f')\nplt.title('Normalized Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.colorbar()\nplt.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## So our model is more likely to make false negatives than false positives","metadata":{}},{"cell_type":"code","source":"plot_importance(XGB_optimal, max_num_features=10);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4. Results and Evaluation\n\n","metadata":{"id":"6pBUk35yTDaL"}},{"cell_type":"markdown","source":"### Conclusion, Recommendations, Next Steps\n\nSo as a conclusion of this project: \n* The best model was XGBoostClassifier with an  accuracy score(98%),  precision score(95.3%),F1 score (93.9%) and the most important metric in our case because we want to reduce false negative is recall score (0.924%).\n* we also discrovered  that the variable that determine the most  if the employee will leave or not are : average_monthly_hours, satisfaction and last_evaluation.\n\n\n\n","metadata":{"id":"9MOMqelNLn2v"}},{"cell_type":"markdown","source":"We recommend to the stakeholders the following actions to retain the employees:\n\n    * Improve employees satisfaction by augmenting their salaries (which is an important factor of satisfaction).\n    * Provide more promotions, especially for employees who have high evaluations.\n    * Reduce working hours, at least to the average.\n    * Offer training and development opportunities for employees who do not perform well (low evaluations)","metadata":{}},{"cell_type":"markdown","source":"The next steps are :\n* Gathering more information about the employees to find out if there are other factors that can influence left variable.\n* Searching for additional sources of employee satisfaction.\n* Attempting to improve model performance.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}